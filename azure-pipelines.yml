parameters:
- name: JOB_PREFIX
  displayName: 'Job prefix used to distinquish workloads'
  type: string
  default: "fmc"

- name: VMSIZE
  displayName: 'VM Size'
  type: string
  default: D48as_v4
  values:
  - D96as_v4
  - D64as_v4
  - D48as_v4
  - D32as_v4
  - D16as_v4
  - D8as_v4

- name: STORAGE_ACCOUNT
  displayName: 'Storage Account'
  type: string
  default: "datastorage2429sa"

- name: INPUT_CONTAINER
  displayName: 'Input Container'
  type: string
  default: "input"

- name: INPUT_PATH
  displayName: 'Input Path in Container'
  type: string
  default: "*.fastq"

- name: OUTPUT_CONTAINER
  displayName: 'Output Container'
  type: string
  default: "output"

- name: OUTPUT_PATH
  displayName: 'Output Path in Container'
  type: string
  default: "."

- name: DESTROY
  displayName: 'Destroy infra after successful run?'
  type: boolean
  default: true

- name: STOPVM
  displayName: 'Stop VM after job?'
  type: boolean
  default: true

- name: SNAPSHOT
  displayName: 'Snapshot data disk after successful run?'
  type: boolean
  default: false

variables:
- name: DECODE_PERCENTS
  value: false

trigger: none
pr: none

jobs:
- job: sequencing
  timeoutInMinutes: 0
  pool: ado-agents 
  # pool:
  #   vmImage: 'ubuntu-latest'

  steps:
  #Setup Custom Variables for pipeline
  - script: |
      GIT_COMMIT=$( git rev-parse --short HEAD )
      NOW=$(date +'%m%d%Y-%H%M%S')
      echo "##vso[task.setvariable variable=commitHash;isOutput=true]$GIT_COMMIT"
      echo "##vso[task.setvariable variable=now;isOutput=true]$NOW"
    name: runtime_var
    displayName: 'Set runtime variables for pipeline'

  #KEY VAULT TASK
  - task: AzureKeyVault@1
    inputs:
      azureSubscription: 'SERVICE-2429'
      KeyVaultName: '$(AZURE_KEYVAULT_NAME)'
      SecretsFilter: 'SP-CLIENTID,SP-PASSWORD,SP-TENANTID,SP-SUBSCRIPTIONID,SA-ACCESS-KEY' 
    displayName: 'Get key vault secrets'

  # TERRAFORM VERSION
  - script: |
      terraform version
    displayName: 'Get Terraform Version'

  # AZ LOGIN USING TERRAFORM SERVICE PRINCIPAL
  - script: |
      az login --service-principal -u "$(SP-CLIENTID)" -p "$(SP-PASSWORD)" --tenant "$(SP-TENANTID)"
    displayName: 'Login az cli'

  - script: |
      # Run Terraform
      set -x
      export ARM_CLIENT_ID=$(SP-CLIENTID)
      export ARM_CLIENT_SECRET=$(SP-PASSWORD)
      export ARM_SUBSCRIPTION_ID=$(SP-SUBSCRIPTIONID)
      export ARM_TENANT_ID=$(SP-TENANTID)
      export ARM_ACCESS_KEY=$(SA-ACCESS-KEY)
      cd iac
      echo '#######Terraform Init########'
      terraform init
      echo '#######Terraform Plan########'
      terraform plan -out="out.plan" 
      echo '#######Terraform Apply########'
      terraform apply out.plan
    displayName: 'Terraform Init, Plan and Apply '

  - script: |
      # Setup and run the sequencing job
      set -x  
      export ARM_CLIENT_ID=$(SP-CLIENTID)
      export ARM_CLIENT_SECRET=$(SP-PASSWORD)
      export ARM_SUBSCRIPTION_ID=$(SP-SUBSCRIPTIONID)
      export ARM_TENANT_ID=$(SP-TENANTID)
      export ARM_ACCESS_KEY=$(SA-ACCESS-KEY)
      cd iac
      terraform output -json private_key | jq -r . > ../ssh_key; chmod 0600 ../ssh_key
      terraform output -json vm_ip | jq -r . > ../vm_ip_address
      terraform output -json vm_name | jq -r . > ../vm_name 
      terraform output -json vm_rg | jq -r . > ../vm_rg
      terraform output -json vm_datadisk | jq -r . > ../vm_datadisk
    displayName: 'Get outputs needed by all scripts and store locally'
  
  - script: |
      set -x
      az vm start -n $(cat ./vm_name) -g $(cat ./vm_rg)
      az vm user reset-ssh -n $(cat ./vm_name) -g $(cat ./vm_rg)
    condition: always()
    displayName: 'Start VM if not running' 

  - script: |
      set -x
      ls -la
      #Initialize the the remove environment
      #cat ./initialize-env.sh | ssh -i ssh_key -o StrictHostKeyChecking=no azureuser@$(cat ./vm_ip_address)
      if [ -f ./initialize-env.sh ]; then
        ssh -i ssh_key -o StrictHostKeyChecking=no azureuser@$(cat ./vm_ip_address) "/bin/bash -s"  <./initialize-env.sh ${{parameters.JOB_PREFIX}}
      else
        echo "no initialize job supplied"
      fi
    displayName: 'Setup job run environment'

  - script: |
      set -x
      echo "Using Storage Account ${{parameters.STORAGE_ACCOUNT}}"
      cat <<-EOF > download-batch.sh
        az login --identity
        az storage blob download-batch --source ${{parameters.INPUT_CONTAINER}} --pattern ${{parameters.INPUT_PATH}} --account-name ${{parameters.STORAGE_ACCOUNT}} --destination /data/input/${{parameters.JOB_PREFIX}} --auth-mode login
      EOF
      cat download-batch.sh
      ls -la
      cat download-batch.sh | ssh -i ssh_key -o StrictHostKeyChecking=no azureuser@$(cat ./vm_ip_address) 
    displayName: 'Download fastq files from storage account'

  - script: |
      set -x
      ls -la
      #Run the job script on the remote agent
      #cat ./job.sh | ssh -i ssh_key -o StrictHostKeyChecking=no azureuser@$(cat ./vm_ip_address)
      ssh -i ssh_key -o StrictHostKeyChecking=no azureuser@$(cat ./vm_ip_address) "/bin/bash -s"  <./job.sh ${{parameters.JOB_PREFIX}}
    displayName: 'Run workload processing job'

  - script: |
      set -x
      #Run the cleaup job passing our local variable to remote machine
      if [ -f ./post-processing.sh ]; then
        ssh -i ssh_key -o StrictHostKeyChecking=no azureuser@$(cat ./vm_ip_address) "/bin/bash -s"  <./post-processing.sh ${{parameters.JOB_PREFIX}}
      else
        echo "no post-processing job supplied"
      fi
    displayName: 'Run post processing job'
  
  - script: |
      set -x
      echo "Using Storage Account ${{parameters.STORAGE_ACCOUNT}}"
      cat <<-EOF > upload-batch.sh
        az login --identity
        #upload run results
        az storage blob upload-batch -d ${{parameters.OUTPUT_CONTAINER}} -s /data/assembly/${{parameters.JOB_PREFIX}} --account-name ${{parameters.STORAGE_ACCOUNT}} --destination-path ${{parameters.OUTPUT_PATH}}/$(runtime_vars.now) --auth-mode login
        #upload job log
        az storage blob upload-batch -d ${{parameters.OUTPUT_CONTAINER}} -s /data/runs/${{parameters.JOB_PREFIX}} --account-name ${{parameters.STORAGE_ACCOUNT}} --destination-path ${{parameters.OUTPUT_PATH}}/$(runtime_vars.now) --auth-mode login
      EOF
      cat upload-batch.sh
      ls -la
      cat upload-batch.sh | ssh -i ssh_key -o StrictHostKeyChecking=no azureuser@$(cat ./vm_ip_address) 
    displayName: 'Upload processing results to storage account'
  
  - script: |
      set -x
      az snapshot create -n $(date +'%m%d%Y-%H%M%S')-snap -g $(cat ./vm_rg) --source $(cat ./vm_datadisk)
    displayName: 'Snapshot data disk'
    condition: ${{ parameters.snapshot }}
  
  - script: |
      set -x
      #Run the cleaup job passing our local variable to remote machine
      if [ -f ./cleanup-env.sh ]; then
        ssh -i ssh_key -o StrictHostKeyChecking=no azureuser@$(cat ./vm_ip_address) "/bin/bash -s"  <./cleanup-env.sh ${{parameters.JOB_PREFIX}}
      else
        echo "no cleanup job provided."
      fi
    displayName: 'Run cleanup job'

  - script: |
      set -x
      az vm deallocate -n $(cat ./vm_name) -g $(cat ./vm_rg)
    condition: ${{ parameters.stopvm }}
    displayName: 'Stop and deallocate the VM'
  
  - script: |
      # Tear down the environment
      set -x  
      export ARM_CLIENT_ID=$(SP-CLIENTID)
      export ARM_CLIENT_SECRET=$(SP-PASSWORD)
      export ARM_SUBSCRIPTION_ID=$(SP-SUBSCRIPTIONID)
      export ARM_TENANT_ID=$(SP-TENANTID)
      export ARM_ACCESS_KEY=$(SA-ACCESS-KEY)
      cd iac
      cd iac
      echo '#######Terraform Destroy########'
      terraform destroy --auto-approve 
    condition: ${{ parameters.destroy }}
    displayName: 'Terraform Destroy'

